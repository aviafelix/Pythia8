<html>
<head>
<title>Multiple Interactions</title>
</head>
<body>

<h2>Multiple Interactions</h2>

The starting point for the multiple interactions physics scenario in
PYTHIA is provided by [1]. Recent developments have included a more
careful study of flavour and colour correlations, junction topologies
and the relationship to beam remnants [2], and interleaving with 
initial-state radiation [3], making use of transverse-momentum-ordered
initial- and final-state showers. The current description is not yet
finished; what is missing is an interleaving also with final-state 
shower evolution and, above all, a more successful scheme to handle
the correlated colour flow in the final state in events with 
complicated multiparton topologies.  

<h3>Main variables</h3>

The rate of interactions is determined by 
<p/><strong>
parameter name="MultipleInteractions:alphaSvalue" default="0.127" 
min="0.06" max="0.25"
</strong><br/>
The value of <i>alpha_strong</i> at <i>m_Z</i>. Default value is 
picked equal to the one used in CTEQ 5L. 
   

<p/>
The actual value is then regulated by the running to the scale 
<i>pT^2</i>, at which it is evaluated
<p/><strong>
mode name="MultipleInteractions:alphaSorder" default="1" min="0" max="2"
</strong><br/>
The order at which <i>alpha_strong</i> runs at scales away from 
<i>m_Z</i>.
<br/><strong>
option value="0"</strong>: zeroth order, i.e. <i>alpha_strong</i> is kept 
fixed.  
<br/><strong>
option value="1"</strong>: first order, which is the normal value.  
<br/><strong>
option value="2"</strong>: second order. Since other parts of the code do 
not go to second order there is no strong reason to use this option, 
but there is also nothing wrong with it.  
  

<p/>
Note that the choice of <i>alpha_strong</i> made here overrides the
one implemented in the normal process machinery, but only for the
interactions generated by the <code>MultipleInteractions</code> class.

<p/>
In addition there is the possibility of a global rescaling of 
cross sections (which could not easily be accommodated by a 
changed <i>alpha_strong</i>, since <i>alpha_strong</i> runs)
<p/><strong>
parameter name="MultipleInteractions:Kfactor" default="1.0" min="0.5" 
max="4.0"
</strong><br/>
Multiply all cross sections by this fix factor.
  

<p/>
There are two complementary ways of regularizing the small-<i>pT</i> 
divergence, a sharp cutoff and a smooth dampening. These can be 
combined as desired, but it makes sense to coordinate with how the 
same issue is handled in spacelike showers. Actually, by default,
the parameters defined here are used also for the spacelike showers,
but this can be overridden.

<p/>
Regularization of the divergence of the QCD cross section for 
<i>pT -> 0</i> is obtained by a factor <i>pT^4 / (pT0^2 + pT^2)^2</i>, 
and by using an <i>alpha_s(pT0^2 + pT^2)</i>. An energy dependence 
of the <i>pT0</i> choice is introduced by two further parameters, 
so that <i>pT0Ref</i> is the <i>pT0</i> value for the reference 
cm energy, <i>pT0Ref = pT0(ecmRef)</i>.   
<br/><b>Warning:</b> if a large <i>pT0</i> is picked for multiple 
interactions, such that the integrated interaction cross section is 
below the nondiffractive inelastic one, this <i>pT0</i> will 
automatically be scaled down to cope.

<p/>
The actual pT0 parameter used at a given cm energy scale, <i>ecmNow</i>,
is obtained as
<br/><i>
     pT0 = pT0(ecmNow) = pT0Ref * (ecmNow / ecmRef)^ecmPow 
</i><br/>
where <i>pT0Ref</i>, <i>ecmRef</i> and <i>ecmPow</i> are the 
three parameters below.

<p/><strong>
parameter name="MultipleInteractions:pT0Ref" default="2.2" min="0.5" 
max="10.0"
</strong><br/>
The <i>pT0Ref</i> scale in the above formula.
<br/><b>Note:</b> <i>pT0Ref</i> remains to be carefully tuned, but this 
has no point before the colour flow description has reached a more 
mature form.
  

<p/><strong>
parameter name="MultipleInteractions:ecmRef" default="1800.0" min="1."
</strong><br/>
The <i>ecmRef</i> reference energy scale introduced above.
  

<p/><strong>
parameter name="MultipleInteractions:ecmPow" default="0.16" 
min="0.0" max="0.5"
</strong><br/>
The <i>ecmPow</i> energy rescaling pace introduced above.
  

<p/>
Alternatively, or in combination, a sharp cut can be used.
<p/><strong>
parameter name="MultipleInteractions:pTmin" default="0.2" min="0.1" 
max="10.0"
</strong><br/>
Lower cutoff in <i>pT</i>, below which no further interactions 
are allowed. Normally <i>pT0</i> above would be used to provide 
the main regularization of the cross section for <i>pT -> 0</i>, 
in which case <i>pTmin</i> is used  mainly for technical reasons. 
It is possible, however, to set <i>pT0Ref = 0</i> and use 
<i>pTmin</i> to provide a step-function regularization, or to 
combine them in intermediate approaches. Currently <i>pTmin</i> 
is taken to be energy-independent.  
  

<p/> 
The choice of impact-parameter dependence is regulated by several
parameters.

<p/><strong>
mode name="MultipleInteractions:bProfile" default="2" 
min="0" max="3"
</strong><br/>
Choice of impact parameter profile for the incoming hadron beams.
<br/><strong>
option value="0"</strong>: no impact parameter dependence at all.  
<br/><strong>
option value="1"</strong>: a simple Gaussian matter distribution; 
no free parameters.  
<br/><strong>
option value="2"</strong>: a double Gaussian matter distribution, 
with the two free parameters <i>coreRadius</i> and 
<i>coreFraction</i>.  
<br/><strong>
option value="3"</strong>: an overlap function, i.e. the convolution of 
the matter distributions of the two incoming hadrons, of the form
<i>exp(- b^expPow)</i>, where <i>expPow</i> is a free 
parameter.   
  

<p/><strong>
parameter name="MultipleInteractions:coreRadius" default="0.4"
min="0.1" max="1."
</strong><br/>
When assuming a double Gaussian matter profile, <i>bProfile = 2</i>,
the inner core is assumed to have a radius that is a factor
<i>coreRadius</i> smaller than the rest.
   

<p/><strong>
parameter name="MultipleInteractions:coreFraction" default="0.5" 
min="0." max="1." 
</strong><br/>
When assuming a double Gaussian matter profile, <i>bProfile = 2</i>,
the inner core is assumed to have a fraction <i>coreFraction</i> 
of the matter content of the hadron.
   

<p/><strong>
parameter name="MultipleInteractions:expPow" default="1." 
min="0.4" max="10."
</strong><br/>
When <i>bProfile = 3</i> it gives the power of the assumed overlap 
shape <i>exp(- b^expPow)</i>. Default corresponds to a simple 
exponential drop, which is not too dissimilar from the overlap 
obtained with the standard double Gaussian parameters. For 
<i>expPow = 2</i> we reduce to the simple Gaussian, <i>bProfile = 1</i>, 
and for <i>expPow -> infinity</i> to no impact parameter dependence 
at all, <i>bProfile = 0</i>. For small <i>expPow</i> the program 
becomes slow and unstable, so the min limit must be respected.
   

<h3>Further variables</h3>

These should normally not be touched. Their only function is for
cross-checks.

<p/><strong>
mode name="MultipleInteractions:nQuark" default="5" min="0" max="5"
</strong><br/>
Number of allowed incoming quark flavours in the beams; a change 
to 4 would thus exclude <i>b</i> and <i>bbar</i> as incoming 
partons, etc.
  

<p/><strong>
mode name="MultipleInteractions:nSample" default="1000" min="100" 
</strong><br/>
The allowed <i>pT</i> range is split (unevenly) into 100 bins, 
and in each of these the interaction cross section is evaluated in 
<i>nSample</i> random phase space points. The full integral is used 
at initialization, and the differential one during the run as a
"Sudakov form factor" for the choice of the hardest interaction.
A larger number implies increased accuracy of the calculations.
  

<h3>The process library</h3>

The processes used to generate multiple interactions form a subset
of the standard library of hard processes. The input is slightly
different from the standard hard-process machinery, however, 
since incoming flavours, the <i>alpha_strong</i> value and most
of the kinematics are aready fixed when the process is called.


<h3>Technical notes</h3>

Relative to the articles mentioned above, not much has happened.
The main news is a technical one, that the phase space of the 
<i>2 -> 2</i> (massless) QCD processes is now sampled in 
<i>dy_3 dy_4 dpT^2</i>, where <i>y_3</i> and <i>y_4</i> are 
the rapidities of the two produced partons. One can show that
<br/><i>
    (dx_1 / x_1) * (dx_2 / x_2) * d(tHat) = dy_3 * dy_4 * dpT^2
</i><br/>
Furthermore, since cross sections are dominated by the "Rutherford"
one of <i>t</i>-channel gluon exchange, which is enhanced by a 
factor of 9/4 for each incoming gluon, effective structure functions 
are defined as
<br/><i>
    F(x, pT2) = (9/4) * xg(x, pT2) + sum_i xq_i(x, pT2) 
</i><br/>
With this technical shift of factors 9/4 from cross sections to parton 
densities, a common upper estimate of 
<br/><i>
    d(sigmaHat)/d(pT2) &lt; pi * alpha_strong^2 / pT^4   
</i><br/>
is obtained. 

<p/>
In fact this estimate can be reduced by a factor of 1/2 for the 
following reason: for any configuration <i>(y_3, y_4, pT2)</i> also 
one with <i>(y_4, y_3, pT2)</i> lies in the phase space. Not both 
of those can enjoy being enhanced by the <i>tHat -> 0</i> 
singularity of 
<br/><i>
    d(sigmaHat) propto 1/tHat^2. 
</i><br/>
Or if they are, which is possible with identical partons like 
<i>q q -> q q</i> and <i>g g -> g g</i>, each singularity comes 
with half the strength. So, when integrating/averaging over the two 
configurations, the estimated <i>d(sigmaHat)/d(pT2)</i> drops. 
Actually, it drops even further, since the naive estimate above is 
based on
<br/><i>
    (4 /9) * (1 + (uHat/sHat)^2) &lt; 8/9 &lt; 1
</i><br/>
The 8/9 value would be approached for <i>tHat -> 0</i>, which 
implies <i>sHat >> pT2</i> and thus a heavy parton-distribution 
penalty, while parton distributions are largest for 
<i>tHat = uHat = -sHat/2</i>, where the above expression 
evaluates to 5/9. A fudge factor is therefore introduced to go the 
final step, so it can easily be modifed when further non-Rutherford 
processes are added, or should parton distributions change significantly.

<p/>
At initialization, it is assumed that  
<br/><i>
    d(sigma)/d(pT2) &lt; d(sigmaHat)/d(pT2) * F(x_T, pT2) * F(x_T, pT2)
       * (2 y_max(pT))^2
</i><br/>
where the first factor is the upper estimate as above, the second two
the parton density sum evaluated at <i>y_3 = y_ 4 = 0</i> so that 
<i>x_1 = x_2 = x_T = 2 pT / E_cm</i>, where the product is expected 
to be maximal, and the final is the phase space for
<i>-y_max &lt; y_{3,4} &lt; y_max</i>.
The right-hand side expression is scanned logarithmically in <i>y</i>, 
and a <i>N</i> is determined such that it always is below 
<i>N/pT^4</i>.

<p/>
To describe the dampening of the cross section at <i>pT -> 0</i> by
colour screening, the actual cross section is multiplied by a 
regularization factor <i>(pT^2 / (pT^2 + pT0^2))^2</i>, and the 
<i>alpha_s</i> is evaluated at a scale <i>pT^2 + pT0^2</i>, 
where <i>pT0</i> is a free parameter of the order of 2 - 4 GeV. 
Since <i>pT0</i> can be energy-dependent,  an ansatz
<br/><i>
    pT0(ecm) = pT0Ref * (ecm/ecmRef)^ecmPow
</i><br/>
is used, where <i>ecm</i> is the current cm frame energy, 
<i>ecmRef</i> is an arbitrary reference energy where <i>pT0Ref</i> 
is defined, and <i>ecmPow</i> gives the energy rescaling pace. For 
technical reasons, also an absolute lower <i>pT</i> scale <i>pTmin</i>, 
by default 0.2 GeV, is introduced. In principle, it is possible to 
recover older scenarios with a sharp <i>pT</i> cutoff by setting 
<i>pT0 = 0</i> and letting <i>pTmin</i> be a larger number. 

<p/>
The above scanning strategy is then slightly modified: instead of
an upper estimate <i>N/pT^4</i> one of the form 
<i>N/(pT^2 + r * pT0^2)^2</i> is used. At first glance, <i>r = 1</i> 
would seem to be fixed by the form of the regularization procedure, 
but this does not take into account the nontrivial dependence on 
<i>alpha_s</i>, parton distributions and phase space. A better 
Monte Carlo efficiency is obtained for <i>r</i> somewhat below unity, 
and currently <i>r = 0.25</i> is hardcoded.

In the generation a trial <i>pT2</i> is then selected according to
<br/><i>
    d(Prob)/d(pT2) = (1/sigma_ND) * N/(pT^2 + r * pT0^2)^2 * ("Sudakov")
</i><br/>
For the trial <i>pT2</i>, a <i>y_3</i> and a <i>y_4</i> are then 
selected, and incoming flavours according to the respective 
<i>F(x_i, pT2)</i>, and then the cross section is evaluated for this 
flavour combination. The ratio of trial/upper estimate gives the 
probability of survival.

<p/>
Actually, to profit from the factor 1/2 mentioned above, the cross
section for the combination with <i>y_3</i> and <i>y_4</i> 
interchanged is also tried, which corresponds to exchanging <i>tHat</i>
and <i>u_hat</i>, and the average formed, while the final kinematics 
is given by the relative importance of the two.

<p/>
Furthermore, since large <i>y</i> values are disfavoured by dropping 
PDF's, a factor 
<br/><i>
   WT_y = (1 - (y_3/y_max)^2) * (1 - (y_4/y_max)^2) 
</i><br/>
is evaluated, and used as a survival probability before the more
time-consuming PDF+ME evaluation, with surviving events given a 
compensating weight <i>1/WT_y</i>. 

<p/>
An impact-parameter dependencs is also allowed. Based on the hard 
<i>pT</i> scale of the first interaction, and enhancement/depletion 
factor is picked, which multiplies the rate of subsequent interactions.

<p/>
Parton densities are rescaled and modified to take into account the 
energy-momentum and flavours kicked out by already-considered 
interactions.

<h3>References</h3>

<ol>
<li>T. Sjostrand and M. van Zijl, Phys. Rev. D36 (1987) 2019</li>
<li>T. Sjostrand and P.Z. Skands, JHEP 03 (2004) 053</li>
<li>T. Sjostrand and P.Z. Skands, Eur. Phys. J. C39 (2005) 129</li> 
</ol>

</body>
</html>

<!-- Copyright C 2006 Torbjorn Sjostrand -->
